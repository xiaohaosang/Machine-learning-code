{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    retArray =np.ones((np.shape(dataMatrix)[0],1))  #分类标签的初始值都设为1\n",
    "    if threshIneq == 'lt':  #\"lt\":less than 小于  \"gt\",greater than 大于\n",
    "        # print(dataMatrix[:,dimen] <= threshVal)\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0  \n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "dataMatrix=np.mat([[1,2,3,4],[2,1,0,3],[2,3,1,3]])\n",
    "stumpClassify(dataMatrix,1,2,'lt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = np.mat(dataArr); labelMat = np.mat(classLabels).T\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = np.mat(np.zeros((m,1)))\n",
    "    minError = np.inf \n",
    "    for i in range(n): # 遍历每一个特征\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps  \n",
    "        for j in range(-1,int(numSteps)+1): # 稍有别于regTree中CART，遍历特征中的每个取值，这里用numSteps替代\n",
    "            for inequal in ['lt', 'gt']: \n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)\n",
    "                errArr = np.mat(np.ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr  # 标签权重*errArr，(1,m)*(m,1),结果为单一数值\n",
    "                # print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40,debug=False):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m,1))/m)   #初始化所有的标签的权重都相同\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)\n",
    "        if debug: print(\"D:\",D.T)\n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error,1e-16))) #计算alpha\n",
    "        bestStump['alpha'] = alpha  \n",
    "        weakClassArr.append(bestStump)   #保存bestStump，即每个弱分类树\n",
    "        \n",
    "        #更新D，即标签的权重\n",
    "        if debug: print(\"classEst: \",classEst.T)\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst) #正确的分类为-alpha，错误的分类为alpha\n",
    "        D = np.multiply(D,np.exp(expon))                                \n",
    "        D = D/D.sum()\n",
    "        \n",
    "        #计算分类误差，误差为零时，退出\n",
    "        aggClassEst += alpha*classEst   \n",
    "        if debug: print(\"aggClassEst: \",aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T,np.ones((m,1))) #计算分类错误的累计和\n",
    "        if debug: print(\"aggErrors:\",aggErrors)\n",
    "        errorRate = aggErrors.sum()/m  \n",
    "        if debug: print(\"total error: \",errorRate)\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr,errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass,classifierArr,debug=False):\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        #每个弱分类树中包括'dim','thresh','ineq',通过stumpClassify，计算出classEst，再*'alpha'，累加得出最后结果\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n",
    "                                 classifierArr[i]['thresh'],\\\n",
    "                                 classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        if debug: print(\"aggClassEst:\",aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    datMat = np.mat([[1,2.1],[2,1.1],[1.3,1],[1,1],[2,1]])\n",
    "    classLabels = [1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return datMat,classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaBoostTrainDS:=====\n",
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst:  [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "aggErrors: [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "total error:  0.2\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst:  [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "aggErrors: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "total error:  0.2\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst:  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "aggErrors: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "total error:  0.0\n",
      "errorRate: 0.0\n",
      "adaClassify:=====\n",
      "aggClassEst: [[-0.69314718]\n",
      " [ 0.69314718]]\n",
      "aggClassEst: [[-1.66610226]\n",
      " [-0.27980789]]\n",
      "aggClassEst: [[-2.56198199]\n",
      " [ 0.61607184]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datArr,labelArr = loadSimpData()\n",
    "print(\"adaBoostTrainDS:=====\")\n",
    "classifierArr,errorRate= adaBoostTrainDS(datArr,labelArr,30)\n",
    "print(\"errorRate:\",errorRate)\n",
    "print(\"adaClassify:=====\")\n",
    "adaClassify([[0,0],[9,0]],classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# 测试两两排列组合\n",
    "import itertools\n",
    "for i in itertools.combinations([1,2,3], 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_dist: [-1.0, 1.0]\n",
      "data: [[1.3 1. ]\n",
      " [1.  1. ]\n",
      " [1.  2.1]\n",
      " [2.  1.1]\n",
      " [2.  1. ]]\n",
      "lables: [1, 1, -1, -1, -1]\n",
      "{(-1.0, 1.0): {'weakClassArr': [{'dim': 0, 'thresh': 1.3, 'ineq': 'gt', 'alpha': 0.6931471805599453}, {'dim': 1, 'thresh': 1.0, 'ineq': 'gt', 'alpha': 0.9729550745276566}, {'dim': 0, 'thresh': 0.9, 'ineq': 'gt', 'alpha': 0.8958797346140276}], 'errorRate': 0.0}}\n",
      "name -1.0 1.0\n",
      "Classify [[ 1.  1. -1. -1.  1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]]\n",
      "[1.0, 1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 以下将adaBoost推广到多分类，方法是将多个分类，通过两两组合，各自训练，最后将所有分类结果合并，计算出频数最高的分类结果\n",
    "import itertools\n",
    "# 训练\n",
    "def adaBoostTrainMutil(dataArr,classLabels,numIt=40):\n",
    "    label_dist=sorted(list(set(list(classLabels))))\n",
    "    print(\"label_dist:\",label_dist)\n",
    "    adaBoost_dict = {}\n",
    "    \n",
    "    # 将标签两两组合，对每个组合单独训练\n",
    "    for i,j in itertools.combinations(label_dist, 2):\n",
    "        # print(i,j)\n",
    "\n",
    "        index_1 = np.nonzero(np.array(classLabels[:])== i)\n",
    "        # print(\"index_1\",index_1)\n",
    "        data_1 = dataArr[index_1[0],:] \n",
    "        index_2 = np.nonzero(np.array(classLabels[:])== j)\n",
    "        data_2 = dataArr[index_2[0],:]\n",
    "        data = np.vstack((data_1,data_2))   #data为标签i，j的训练集，lables为标签\n",
    "        lables =[1]*data_1.shape[0]+[-1]*data_2.shape[0] \n",
    "        print(\"data:\",data)\n",
    "        print(\"lables:\",lables)\n",
    "        \n",
    "        \n",
    "        #(i,j)组合下训练的adaBoost_dict[(i,j)]\n",
    "        this_adaBoost=adaBoost_dict[(i,j)]={}        \n",
    "        this_adaBoost['weakClassArr'],this_adaBoost['errorRate']=adaBoostTrainDS(data,lables,numIt) #\n",
    "    return adaBoost_dict\n",
    "\n",
    "  \n",
    "       \n",
    "adaBoost_dict = adaBoostTrainMutil(datArr,labelArr,numIt=40) \n",
    "print(adaBoost_dict)\n",
    "\n",
    "from collections import Counter\n",
    "# 预测\n",
    "def adaClassifyMutil(datToClass,adaBoost_dict):\n",
    "    pred_labels_array = None\n",
    "    for name,value in adaBoost_dict.items():\n",
    "        value_1,value_2 = name\n",
    "        print(\"name\",value_1,value_2)\n",
    "        this_classifierArr = adaBoost_dict[name]['weakClassArr']\n",
    "        Classify = adaClassify(datToClass,this_classifierArr)\n",
    "#         print(Classify)\n",
    "#         print(np.nonzero(Classify==1)[0])\n",
    "#         print(np.nonzero(Classify==-1)[0])\n",
    "#         print(Classify[np.nonzero(Classify==1)[0],:])\n",
    "        Classify[np.nonzero(Classify==1)[0],:] = -99   #增加两个中间变量\n",
    "        Classify[np.nonzero(Classify==-1)[0],:] = -101\n",
    "        Classify[np.nonzero(Classify==-99)[0],:] = value_1 #将分类1转换为原来的value_1，\n",
    "        Classify[np.nonzero(Classify==-101)[0],:] = value_2 #同理上\n",
    "        print(\"Classify\",Classify.T)\n",
    "        if pred_labels_array is None:\n",
    "            pred_labels_array = Classify\n",
    "        else:\n",
    "            pred_labels_array = np.hstack((pred_labels_array,Classify)) #将所有结果合并\n",
    "            \n",
    "    print(pred_labels_array)\n",
    "    y_pred = []\n",
    "    for labels in np.array(pred_labels_array):\n",
    "        # print(\"labels\",labels)\n",
    "        pred = Counter(labels.flatten()).most_common(1)[0][0] #计算出频数最高的分类\n",
    "        y_pred.append(pred)\n",
    "    return y_pred\n",
    "        \n",
    "y_pred = adaClassifyMutil(datArr,adaBoost_dict)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_dataset=datasets.load_iris()\n",
    "data_x = iris_dataset.data\n",
    "data_y = iris_dataset.target\n",
    "x_train,x_test,y_train,y_test=train_test_split(data_x,data_y,random_state=0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_dist: [0, 1, 2]\n",
      "data: [[4.7 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.8 2.7 4.1 1. ]]\n",
      "lables: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "data: [[4.7 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.  3.  4.8 1.8]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [7.7 3.8 6.7 2.2]]\n",
      "lables: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "data: [[5.9 3.  4.2 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.  3.  4.8 1.8]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [7.7 3.8 6.7 2.2]]\n",
      "lables: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "name 0 1\n",
      "Classify [[1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      "  1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.]]\n",
      "name 0 2\n",
      "Classify [[2. 2. 0. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 0. 2. 2. 0. 0.\n",
      "  2. 0. 0. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 2.]]\n",
      "name 1 2\n",
      "Classify [[2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.\n",
      "  2. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 2.]]\n",
      "[[1. 2. 2.]\n",
      " [1. 2. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]\n",
      " [1. 2. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]\n",
      " [1. 2. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]\n",
      " [1. 2. 2.]\n",
      " [1. 2. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 2.]]\n",
      "Test set score:0.89474\n"
     ]
    }
   ],
   "source": [
    "adaBoost_dict = adaBoostTrainMutil(x_train,y_train,numIt=50) \n",
    "y_pred = adaClassifyMutil(x_test,adaBoost_dict)\n",
    "print('Test set score:{:.5f}'.format(np.mean(y_pred==y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:0.97368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         n_estimators=40, learning_rate=1)\n",
    "bdt.fit(x_train, y_train)\n",
    "y_pred = bdt.predict(x_test)\n",
    "print('Test set score:{:.5f}'.format(np.mean(y_pred==y_test))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
